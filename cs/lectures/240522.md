# May 22, 2024 System Design Day 3

## Follow-up on questions
- when explicitly adding a join table in between many-to-many relationships
  - when you make that join table explicit you make 2 separate 1:many relationships
  - example of students - enrollments - classes
    - a student can have many enrollments, but an (individual) enrollment can only have 1 student
    - each record needs to be 1 instance of a thing (e.g., 1 enrollment)
    - the crows feet will point to the join table

- application servers vs runtime
  - runtime:  the environment in which you code compiles and is executed
  - the node runtime includes an http module which handles and responds to HTTP requests:  that part is the application server


## Reviewing HW (Twitter ERD)
- Team 3 ERD (also saved as PNG): https://excalidraw.com/#room=a06f778f383b21c146fe,1me87B7J1FvLf5X3DuMtvA


-Team 2:
  - tweets table captures both original tweets and re-tweets
  - the "original_tweet_id" attribute would be self-referential, if null, it's an original tweet
    - they picked tweet and re-tweet as self-referential since all aspects of tweets must also apply to re-tweets

  - used calculated values for likes (an attribute tweet.like_count, but also stored in a separate table "likes")
    - this would allow for availability over consistency (accuracy (on an interval, it would calculate the number of likes to populate the tweet.like_count)
    - this makes sense: how to update?
      - could write a record to likes table and increment calculated value together
      - or use time-based updating every few minutes
        - use a **"cron job"** - a linux utility to execute some file or script on a time-basis
          - it means that script is executed on a time-based interval
          - "daemon" - implies a background process - a cron job will also be a background process (a daemon)
            - it happens automatically in the background


  - this team didn't handle replies


- Q&A:  how to we store video / images?
  - video and images are not stored in the database - that media is stored in media servers and a reference to that location on the media server is stored in the db
  - timestamps are always included in table records:  created_at and updated_at
    - could use index on timestamp and use that to improve query and cron jobs (i.e,. just search within a timestamp)

- followers:
  - in a production environment:  typically would be 1 table (like w proposed)
    - stuff would be cached (and the cache updated in "real-time" as appropriate) to allow for fast display of followers / feed, etc.
    - this pushes more logic to the application layer
  - in a read-heavy environment, do more work at write-time
    - e.g., for recent timelines, inject most recent tweets into a cached timeline with most recent tweets from all the people I follow
  - generally you keep things in 1 table - you wouldn't have a 100 million tables for each user

## In-class Exercise (LS Quiz ERD)
- Team 3 work:  https://excalidraw.com/#room=a06f778f383b21c146fe,1me87B7J1FvLf5X3DuMtvA

- Team 4:
  - used eraser.io
  - see saved T4-LSQuizERD.PNG

  - struggled with logic in code vs data in db
  - question from Nick:  if a user starts a new quiz - what would happen in the db?
    - a new QuizResult should be created
      - associated a score and a user
      - so Quiz and User don't need to be connected - 
    - how do you connect a quiz to a series of question?  quiz is connected to a single question

- comments from Nick:
  - all tables will have a created_at and created_by
    - worrying about whether or not there's a trail of admin making changes to quizzes (i.e., the connection of Quiz to User) doesn't really need to be shown
    - it's probably better to think higher level (i.e., it's NOT a physical ERD - doesn't need every single linkage)
    - it makes sense to show connections that explicitly relate to use cases
    - to address changes to quizzes:
      - changes in tables for small changes
      - new quizzes require entirely new quiz entry (publishing an entirely new quiz)
      ip

### Actual LS Quiz tables
- postgres db
- 2 key tables:
  - "Quiz"
  - "UserQuiz"
  - (also have a "User" table)

- "Quiz":
  - id PK
  - title
  - body --> jsonb (allows postgres to be a document store and act more performantly - all question, options, metadata, etc.)

- "UserQuiz"
  - id PK
  - quiz_id FK
  - user_id FK
  - body --> jsonb
    - changes (like answers) modify this object and re-insert it into the table
    - this data is parsed by application data
    - a jsonb column allows you to efficiently store a document in a relational db
    - could also use a mongoDb to store a the actual document and then store a reference to that mongoDb record in postgres

 
- advantages of this method:
  - removes need for complex queries / joins (reads and writes)
  - versioning is baked in (no need to worry about saving versions so that people can refer back years later)
    - can always update quizzes
  - this implementation is effectively like using postgres like a noSQL db
    - they went with postgres instead of mongodb since they were already using postgres
    - if you were assessing this from scratch, may want to look at the features and options available in mongo vs what's possible in jsonb within postgres
  - easy to understand - less things to go wrong



- disadvantages of this method:
  - storing duplicate copies of the quiz isn't an efficient use of space
    - note that storage is cheap (at the scale of LS and LS students, there isn't much space required - i.e,. no need to optimize for storage in this use case)
  - very hard to do analysis on things like individual questions (have to scan every single quiz, parse in app code, then analyze)
    - however, marks don't count, and quizzes are just there as learning aid
  - complexity is pushed into application code (i.e., making a quiz, quiz structure, etc.), jsonb field
  - when parser breaks - it's a lot of trouble (uses markdown)
  - no flexibility to generate questions on the fly, etc.




## Database design tips
- need to design things that you understand - it's hard to design something you don't really understand
  - e.g., payment processing workflows may be specific, specific business workflows
- shouldn't to learn about an unknown domain

- extract entities from the use cases
- focus on basic relationships
  - 1:many or many:many are most important
  - don't need to worry about constraints initially (this is later, if we do a schema)

- avoid spiderwebs - could be an indication you aren't being thoughtful

- watch entity vs table attribute
  - it will depend on how relevant things are to the app, business domain

- watch out for implied entities

- validate assumptions with interviewer

- think about performance vs accuracy
  - e.g., vote count : add an attribute instead of truly querying votes table

- don't think about your design as being "better" - think about what it's optimized for
  - don't present your design as being just "better"
  - talk about pros and cons of your assumptions
    - assumptions are critical - build around those assumptions
    - discuss the tradeoffs and the boundaries of decisions

- roll with changes that the interview may make
  - they could be looking for limits of abilities / knowledge
  - they could be see how you react to changes

- be aware of non-UI concerns (these things may not come up in interviews):
  - e.g., security, logging, etc.
  - managing state, etc.


- common issues in industries, etc.
  - how to find production issues: may need to try and replicate
  - may need to get data from a dev ops person (through pairing)
  - may end up getting a prod db data dump (cleansed?)
  - need to understand app-level (code-level) constraints vs db-level constraints
  - be aware of what frameworks are doing for you
  - be aware of all of the different ways to enter data into the db:
    - e.g., devs may insert directly, different apps may access the same db

- data validation:
  - have level at app-level (i.e,. front-end UI validations)
  - back-end API validations (e.g., in express routes)
  - db constraints (part of schema)

  - generally you should use all 3 levels of validations

  - at the dev level, db constraints may be a bit looser, etc
    - it can be hard to create test data, etc.




