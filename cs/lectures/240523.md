# May 23, 2024

## Question discussion:
- front-end is usually what runs on the client browser (i.e., react files - html, js, css)
- some readings may call a web server an app server instead
  - watch out for different terms being used in different ways
  - if it looks and smells like an app server, it's an app server (according to our terminology in 3-tier architecture)

## Scaling (future state)

### Quick review:
- web server functions:
  - respond to http requests
  - reverse proxy
    - this is just forwarding requests

  - serves static content
  - load balancing : direct traffic between multiple instances of the same application
  - routing : direct traffic between different applications - i.e., based on a path, where do things go
  - "front door" : restrict traffic
  - caching

- application server functions:
  - app logic
  - interface with data layer
  - creates dynamic content

- database functions:
  - persist data


### Scaling the 3-tier architecture
- database is the first thing we need to move off of a single node
- but typically app server is constrained first since each instance needs to load another instance of the app in memory

- the things below are collectively referred to as "N-tier architecture"

#### Problem 1:  single app server > multiple app servers
- once vertical scaling is no longer possible / effective, need to horizontally scale app server
- horizontally scale:
  - add instances (nodes) of application server
  - will then need a load balancer
  - note:  not all instances of the app server may be exactly the same;  some may be more powerful, have more resources, etc.
  - then web server will server more as a load balancer

#### Problem 2: managing session state
- if there is application state (session data):
  - e.g., a shopping cart

  - that state must be shared by all servers (e.g., cache)
  - or session requests must be routed to the same server
      - use IP, etc.


- cache:  something that stores data so that requests can be served more quickly (implies not a source of truth)
  - but cache can ALSO serve as a source of truth for session data
  - can be drawn anywhere near the app server - above, below, beside
    - but should be near the app server


- for shared application state, can create a key/value store cache
  - cache will be stored in memory (it's faster)
    - but it's not persistent
  - conceptually, we should define specific caches for specific data
    - implementation-wise, those caches may all be on the same machine, but they could also be separate - it would depend
  - typically Redis or Memcached would be used
    - Redis might be easier
    - Memcached could also be used

- read-through cache  vs  cache-aside cache
  - read-through cache: exists before the app servers - to reduce traffic to application server
    - these can be a bottleneck
  - cache-aside cache:  e.g., shared state cache - typically doesn't act as a bottleneck


- for session id:
  - typically add an identifier which is set in a cookie and is then passed with each request from the user so we can identify them
    - there may be an expiration on that id
  - redis is a common key-value store for session data


#### Problem 3: add read replicas w/ load balancer
- with more app servers, there will be more request to the database
  - most dbs can handle 1,000 QPS (in this order of magnitude)
  - note that partitioning (sharding) is different than horizontally scaling
    - too many requests to the store : horizontally scale
    - too much data in the store : shard

- typically might separate read and write dbs first
  - more read dbs than writes (for read-heavy application)
  - additional "read-replicas" will handle read queries
  - "Primary" database will handle write queries

- how to spread read queries?
  - add a load balancer in front of read replicas
  - read replicas are scaled in the same way as app servers with load balancers

- introduced problem:
  - need to keep replicas in sync
  - as you write to the primary db, need to update the read replicas
  - *solution*: need to use a "write log"

- write log:  will propogate changes to read replicas
  - called "eventual consistency" - replicas will eventually be consistent
    - data will be highly available - read replicas will continue to be online and available for requests
    - BUT, write log may not have updated the read replicas, yet
    - can route "latency sensitive" reads to the primary
       - need to handle this in the application code (but it may be handled by a framework in the app code)
    - eventual consistency is okay for social media, but may not be okay for real-time stock quotes

  - write logs: are part of the guarantees that data won't be lost
    - data is written to the write log first before it's appended to the db


- write logs are a configuration of mysql
- read replicas:
    - are separate instances of the db that need to be setup and then synchronized with the primary


- relational dbs are optimized for reads and "slicing and dicing" data
  - typically, relational dbs are less optimized for write


- caching is typically use-case specific
  - could also cache db read requests - just depends on the info, use case, etc.
  - there are typically caches all over the place
  - cache validation is NOT easy - understanding if the info in cache is current or not is one of the classic difficult problems in comp sci
  - cache - need to pick the right algorithm to manage cache data
    - cache-hits vs cache-misses: need to optimize that algorithm to improve cache-hits



## Misc
- write-heavy apps:
  - e.g., writing data from IOT devices
  - e.g., google docs, editing apps

- webservers - can remove webservers from scaling considerations
  - these can handle 100's of thousands, or millions of hits / second
  - hardware webserverse can handle a lot - can typically just throw money at this problem

- for app servers:  estimate memory footprint
  - if you have 16gb of ram
  - need to estimate size of app
    - will be sum total of all memory requirements (libraries, call stack, etc.)

- for dbs:
  - generally 1 db handles 1000 QPS

- for storage:
  - assume 1 byte = 1 character


- push vs pull
  - pull:  at display time, a request / retrieval occurs
  - push:  something is pre-computed and cached so that it's ready at consumption-time

  - may want to pick a different approach depending on how many people, etc.

## Review in-class exercise (Netflix ERD)
- could use a self-referential "parent_title" for the "shows" instead of an additional table, like we did

- remember that metrics should be calculated according to the use cases provided
  - need to clarify differences between different types of reads / writes
  - if calculating storage requirements, need to separate db requests from media storage requests - those are different entities

- remember, there are limits to the size of the fields in relational databases
  - based on data type
  - will vary by database (e.g., postgresql vs mysql, etc.)


## Review HW

### Cache
- cache:
  - extremely fast
  - protects db and prevents you having to scale the db

  - cons:  
    - complexity, code logic, hard to debug
    - cache invalidation challenges
    - if cache goes down and you're heavily reliant on them, those requests go to app server / db
      - "thundering herd problems" : if the cache goes down, then your db will also go down, since it wasn't setup to take on that volume of requests

- the pros are very big pros
  - scaling db is hard

- cache-aside:
  - hit the cache first, if it's not there, then hit db and put it into the cache
  - requests will hit the app server first
    - can speed requests to db, etc.
  - won't crash app server if it goes down, but if it's protecting the db, then the db could go down

- read-through cache:
  - a "smart" cache: the cache will get hit first before hitting the app server
  - in this situation, if the cache goes down, you can crash the app server



### CDNs
- static assets things that are large, requested frequently are best for CDNs
- 3rd parties - you can't do anything if the CDN goes down

- example:
  - loading a basecamp page
  - the initial page request goes to basecamp
  - then additional requests go out to the CDN
    - most of those are static, so it goes out to CDN
    - reduces latency, takes pressure off basecamp servers

  - why is the URL for assets so long?
    - long ids are used as a fingerprint to identify the unique version of the asset
    - called a **"cache buster"** : the URL is long to prevent the browser from using it's internal cache to serve up a file that may have the same name
  
- CDNs use compression, minification, remove whitespace, comments, etc.
  - mangling - make the code harder to understand to make reverse engineering harder

- the browser itself is making the requests that go to the CDN




## Discussion Session
- static vs dynamic load balancing

  - static: inflexible algorithms, algorithms based upon fixed parameters (e.g., hardware specs)
    - e.g., round robin
  - app servers may not be the same, so may want a different percentage of traffic allocated to each based upon hardware spec

  - dynamic:
    - allocating based upon real-time parameters
    - i.e., actual traffic, actual network latency, etc.
    - shedding load:  dropping requests, slowing the app, etc.


- cache-aside vs read-through cache
  - cache-aside:  the app-server does the work to check the cache and put data into the cache

  - read-through cache:
    - could be a CDN:
      - considered a read-through for requests for static files, even though it's sort of "aside"
    - could be in front of app server
    - could be in front of db
    - the reading goes to the cache and then THROUGH the cache to whatever is behind it
      - it creates bottleneck - it becomes a piece of the stack
      - it sits in-between 2 things

- see capstone project "willow" 
  - change data capture pipelines
  - automatically updates a cache
    - prevents cache invalidation issues
  - this is also code; but not part of your core application business logic
  - all "framework" stuff

- fundamental principles:
  - replication:  make copies, solves traffic problem
  - partitioning: splitting things up, solves volume problem

- cache invalidation vs cache eviction

  - cache invalidation: focuses on stale data
  - cache evication: focuses on free up memory

  - Nick would consider these to be the same thing
    - if the cache is full
    - however, if the cache isn't full, it may depend on invalidation - to determine what to get

    - e.g., most recently watched episode of a show is the least likely to be watched again
    - e.g., sometimes the most recently used needs to be kept in case it comes up again

    - data prioritization is a basic challenge of cache


- systems design questions: how do we practice for these?
  - it's hard to come up with these
  - we review the exercises
  - https://interviewing.io/guides/system-design-interview
  - practice with the system design book
  - best to know what you don't know
    - better to have some idea and venture a guess (trying not to BS)
    - instead of just "I don't know"

- are CDNs secure?
  - so many companies use AWS
  - so if AWS-East goes down it affects a lot of companies and it has an outsize impact on the internet
  - but some CDNs have much more reliability since they can build in more redundancy

- Interesting reading from Chris:  https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/


## Homework


No order of operations for today's homework, complete in any order.

Individual Readings/Videos

    Watch this talk on [Why Are Distributed Systems So Hard?](https://www.youtube.com/watch?v=bG9AQ9ce5Zo) to learn about some of the problems associated with distributed systems and the basics of the CAP theorem
    Watch [this video](https://www.youtube.com/watch?v=VRm2UMsFVz0) for a quick rundown on ACID transactions
     Read DDIA ( Designing Data-Intensive Applications): 
        Chapter 1 for an introduction on important concerns for applications
        Chapter 2 - pg. 27-35 only; beginning of chapter until "Are Document Databases Repeating History?" - for an introduction on data stores that don't use a relational model
        Part II intro - pg. 145-148; Part II intro until Chapter 5 beginning - an introduction to distributing data
        Unreliable Networks - pg. 277-287; stop at Unreliable Clocks - on the different ways networks are unreliable



Group Work - Request Bin

You'll build RequestBin as a team next week and deploy it onto your VPS. Study the below items together as a team and discuss them to make sure everyone's understanding is correct. Start to brainstorm ideas about how you might go about implementing this.

    Watch or read [Tacklebox](https://tacklebox-webhooks.github.io/case-study.html) for intro to Webhooks. You can stop after webhooks are covered as the rest of the project won't be important for this homework. 
    Study: [RequestBin](https://requestbin.com/)
        Click "Create a public bin instead" under the blue button. You shouldn't sign in. We don't care about any of the additional "connect API" or "http workflow" functionality they offer, just the request bin endpoint and viewing requests.
        What is it? What specific problem does this solve? Has anyone on your team used it before, and if so, what was your experience?
        Start thinking about what a prototype of this would look like
    Study: [ngrok](https://ngrok.com/)
        What is it? What specific problem does it solve?  Has anyone on your team used it before, and if so, what was your experience? 
        Why is it useful when we're integrating with webhooks?
        Complete ngrok's [Getting Started tutorial](https://ngrok.com/docs/guides/getting-started/)
    Design: RequestBin ERD
        Come up with ERD for request bin
            Timebox to 20-30 minutes
        Study Github's webhook feature and use it to connect to a request bin on https://requestbin.com. Basecamp also has a webhook feature. Try it out and compare/contrast it with Github's.


VPS + RequestBin: Collaborating with Github

Tomorrow and all of next week we will be building a RequestBin which we will then deploy onto our homegrown deployment infrastructure (our VPS from this week). This will be a team project and will be good practice for your Capstone project on learning how to collaborate on a code project together. Please experiment with how to work with each other. We've seen grouping people into pairs to be really effective, but we've also seen people enjoy individual research and prototyping efforts, and then bring that work back to the larger group. Whatever team dynamic you choose, feel free to experiment and see what type of work fits the personalities on the team. 

Please watch the below two videos for some ideas on how to collaborate:

    [Collaborating on Github](https://www.youtube.com/watch?v=MnUd31TvBoU&t=77s)
    [How to resolve merge conficts in git](https://www.youtube.com/watch?v=xNVM5UxlFSA)

We also recommend managing project tasks on a shared task list or kanban board like [Trello](https://trello.com/).


## Homework Notes

### ACID transactions
- A: atomic:  all or nothing
- C: Consistent: after the transaction, all data will still be valid
- I: Isolated: statements are executed in a seemingly sequential way (i.e., even if statements are executed concurrently, the result will be as if they were executed sequentially)
- D: Durable: changes are committed permanently

- some DMBS use "BASE" properties instead

- example:  bank transfer money from 1 account to another
  - first:  select
  - then 3 updates