# Tues May 28, 2024 (System Design Week 4 Day 2)

## Scaling 3-tier to N-tier
- how do we know when to scale the app server?
  - if the App is 250 mb, and RAM is 16gb
  - simplistically, could have up to 64 simultaneous instances which equates to 64 simultaneous users on a single app server
    - realistically, it will be less than 64: OS overhead, etc.
    - not all processes will be concurrent, etc.

- would we consider CPU usage? for scaling an app server?
  - we wouldn't typically worry about CPU usage
  - there is a balance of utilization vs performance
    - don't necessarily want 100% utilization
    - beyond 80% of *system resources* then it's good to spawn another server to ensure you don't max out, since things will slow down

- in production: spinning up servers are typically spun up automatically based upon thresholds
  - use of numbers is primarily for estimating current state

- thinking about concurrent users:
  - e.g., ticket master example:  14 million concurrent users doesn't necessarily mean 14 million / 64 simultaneous users (on each app server) = req'd number of app servers
  - in reality, the use of additional system components would reduce the number of simultaneous users than hit the app server
    - e.g., use of CDNs, use of cache, etc.
    - also remember that app servers are dynamically spun up depending on threshold values from traffic


## Performance
- see basecamp notes

- improving performance can delay scaling (which is a lot of work)
  - performance is a problem you have all the time (i.e., not a peak traffic thing)


- how do you handle performance of a slow page?
  - a common question in interviews
  - this is a performance issue
  - on the back-end, it's all about the db generally
  - performance isn't an objective standard, different things may need to happen depending on the page

- indexes change O(N) search to O(logN) by sorting data
  - we increase the amount of space used
  - increases write/update times

- N+1 issues:
  - when an app needs to get a set of related records, but executes those records in an inefficient way
    - e.g., JOIN would be more efficient than running N queries for the main records, and then another query for each of those records to get something else
    - latency in SQL queries is typically from the back and forth of opening / closing queries, hence N+1 is inefficient

- ORM:  Object Relational Mapping
  - creates a mapping between the SQL db and the object-oriented app code
  - ORMs can construct inefficient queries

- inefficient query calls can be especially problematic on the front end, if the react code is trying to make many slow queries over the internet


## Replication
- about solving the issue of too many requests for the data
- primary use read replicas
- could also use primary-primary replication
  - introduces conflict resolution requirements

## Partitioning
- solves the problem of too much data within a single store
  - hence the stores need to be split up

- in interviews, don't offer sharding or horizontal scaling of dbs unless you're being pushed that way
  - it's an irrevocable change - make sure you understand the gravity of that option
  - if you've done everything else you can do, then you can consider sharding
  - if sharding a "books" table, do we replicate the "authors" table?
    - would depend on use case - depends on query speeds, etc
    - could split up authors to correspond to the books shards
    - generally, want to minimize the cross-shard queries, otherwise, it's very difficult

- sharding is typically very app logic intensive
- too much sharding can be bad - increases the chances of cross-shard querying
  - so you don't want to shard too much, either



- consistent hashing isn't used as much for NoSQL dbs
  - we do think about sharding for NoSQL dbs, but we think about it a bit differently




