# Wednesday June 19, 2024 - W7D3

## Next 3 days
- working on a full stack project and a live interview project
- it's enough for 90% of folks (likely that you won't finish everything)

- full stack project:
  - given boilerplate code - need to debug
  - need to write tests
  - need to implement pagination

  - read the readme file
  - don't skip challenges - there may be some spoilers (defeats the purpose of the exercise)
  - need to test with jest
  - implement pagination

  - a js project
  - may need to downgrade node to 16.x (this is an older project)
  - no time limit
  - when you finish all challenges, we'll get a live interview challenge

## Notes on meeting with Nick
- update from Thomas:  putting together a skateboard
  - front-end file, chunking a pdf, need to connect with embedding and vector db

- Thomas:  question on further research / refinement on use cases
  - a core problem in the space is chunking, so that when they query the get results similar to what they want
  - solutions may be libraries, etc. 
  - is that the right direction to be searching?
  - is that the right interpretation of what Thomas heard from Max/Nick on Monday
    - i.e., further refine use case to see what the struggles are and what people are talking about

  - Nick: big caveat - Nick isn't familiar with the space
    - can't provide specific details to look into
    - think that part of the research should be into the problems that people are having
    - also talked about looking into making the use case more specific
      - don't just focus on "upload a pdf and talk to it"
      - the way we talk with different types of documents or the requirements for different types of documents are different
      - refine our use case so that we know a particular person in a particular application would use our project
      - also define the perspective: for an end-user (someone who wants to ul a pdf) or a dev (someone who wants to embed the functionality to talk with documents that other users may have)
      - as we build, the complexity should become more apparent
      - hence, they push us to prototype more quickly, more should come out of it
      - specific areas of our domain may be unknown

  - generally, Nick/max think that there is enough engineering work around - since people are working on projects (e.g, chatDoc should be employing engineers)
  - if chunking is a problem in this space, what are the ways in which people approach chunking?
    - when do they reach for different chunking solutions?
    - this may guide us towards specific types of use cases
  - we could look at libraries that do some of the heavy lift
    - to scale the complexity, we could try not using a library (e.g., writing it ourselves)
    - just because there's a library doesn't mean that we should reach for it
    - there may not be a good business reason for writing it yourself, other than you want to be able to talk about those pieces

- Thomas:
  - thinks interesting areas of refinement: 
    - e.g., plug in Python documentation and chat about that documentation
    - expanding that - docs could be different, which might make it difficult
    - e.g., code documentation: could be to allow someone to develop a library to connect to a chatbot with RAG to learn more about that library
  
  - Nick agrees that those could be areas of refinement


- things may not happen sequentially
  - as we start to prototype and work on a use case we may end up changing the use case
  - we should start with a direction and not be everything for everyone

- Nick:
  - is there a concern that this is too small for a capstone project?
  - start to think about how scaling might work
  - could look at a chatbot site:  have a consumer-facing (ul docs) and a business product (use their API to build your own chatbot)

- Thomas:
  - another concern: finding the balance between software eng problems vs. ML problems
  - has been trusting Max's instinct that there's enough here to solve software engineering problems
  - What does Nick think?

  - Nick:  thinks there are enough software engineering problems
    - he's not close enough to the project to know about those
    - could just make calls to OpenAI to solve machine learning piece
      - could use that for embeddings
      - could use that for LLM response
      - don't have to touch other pieces much
      - we just interact with the API
    - there should be a pretty clear line of delineation between software eng vs ML

    - would guess that scaling problems, text parsing problems, storage problems, have a chunking problem (exists within the ML space, but is also a software eng problem - separating text into discrete pieces)
    
    - after we start to think about those topics, then we can think about features to expand complexity (e.g., offering AND framework)

    - believes that there are things in the space that we just don't perceive right now
      - as we do more work, we should start to see those things

- Thomas:
  - scaling 1 user ul's 1000s of docs VS 1000s of users ul 1 doc
    - Nick:  how might these 2 paths differ?
    - Thomas:
      - more than 1 user, more requests to server
      - ...
    - Nick:  storage-wise: have the same number of docs
      - if we get more docs, how do we store? how do we retrieve?  how do we associate them with the user?
      - 1 user vs 1000 users is a traffic problem
      - with 1 user, they can only type so fast
      - this is db replication vs db partitioning
        - 2 different aspects of scaling
    - Thomas:
      - using ChatDoc as a model: does it make more sense to scale more users?
    - Nick:
      - scaling storage is a trivial problem these days
      - problems with document will be less about raw text, Nicks' guess: the problems will be more about parsing, chunking, presentation
        - for users:  should have a plan for how to scale, so if we did have a spike, how would we handle it - we should be thoughtful
        - near the end of the project, we could consider load testing - e.g., mock the OpenAI calls and load test
          - see how the application scales.  See what the boundaries are

- James:
  - LS example again - too specific?
  - Nick:
    - for capstone write-up, probably don't want to focus on just LS
    - hence, may make sense to broaden a bit
    - could think about Khan Academy
      - what happens with different kinds of media
      - can we create a framework to handle various kinds of media
    - if we start with text and it's too easy, then we could extend to an additional media type
      - this might introduce more complexity that we can start to talk about as part of our write-up
    
- Nick:
  - you aren't likely to find a showstopping issue around RAG
    - it doesn't look like we'll need to back out of RAG
    - if we like it, we should be able to commit to the topic and then adjust as we go
  - have had projects aimed at coding students
    - e.g., umbra, e.g., pennant, e.g., spinning up student dev environments
    - students learning could be a use case
    - wouldn't call out LS specifically - too much "dogfooding"
  - we can evolve our use case as we go
    - the use case can be a bit floating
    - can be adjusted, expanded, contracted, based upon how implementation goes
    - by the time we get to the write-up, it should make coherent sense for the write-up
    - user / use case should pass the "sniff" test so that we can talk about it with external parties

  - it might help to look for more specific chatdoc examples
    - they have a product AND an api
    - their product is ostensibly just the API with a front-end
    - if you have the API / back-end system and interact with it, you can expose the API for others

- Thomas:
  - the chatdoc PDF parser is still on a waitlist


- Thomas:
  - e.g., if we wanted to offer a RAG-as-a-service 
    - is it too much to stipulate that our input is only in markdown?
    - Nick:  it could be a safe assumption that text for our website is in markdown or json, etc. (e.g., from a CMS)



- Nick:
  - guideposts are vague - each team will move at a different rate
  - don't rush to something if we feel like we need to hit an arbitrary guideline
  - the guideposts are rough
  - the project mentor will be online on Monday
  - best case, we have a more specific vision of what we're looking at
    - we can writeup a use case
    - short analysis of the model project
    - description of what we envision the final to look like

  



