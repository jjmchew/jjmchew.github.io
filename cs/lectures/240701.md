# Mon Jul 1, 2024 - meeting with Chris (on RAG)

- intros:
  - hybrid is very popular - people are back into the office for many companies

- where are we on readings and research
  - RAG is very new - not a lot of books are available - need to piece that together
  - do practical deep learning for coders up to and including from-scratch model
    - just be aware of this
    - we probably won't create or fine-tune models
    - we should be aware of the vocabulary of ML
    - there is long-term benefit to the vocab in this space

- MS course - is more of a sweet spot for RAG
  - sometimes a video an an article, etc.
  - Ben: on lesson 6 - took a couple hours to get to lesson 6
  - try to finish this course in a few days

- there will be some books that are worth looking at

- there seems to be 1 RAG book we'll get later

- typical capstone project:
  - would have picked observability w/ feature flags, etc.
  - they would be looking for an existing project that they could study
  - for us, we can find a random company, but we need to understand why first
  - e.g., "rag pipeline evals" - we still need to understand what that really means
  - in this domain, looking for a project should be much easier
    - the industry is new so whatever we talk about should be new / niche
    - we don't want to pick a superficial project
    - in RAG, there are a lot of superficial projects - don't need to be quite as niche
    - everything is new so it's okay
    - by this time next year, our project probably won't mean much
    - we need to communicate our understanding of the domain - need to know how people are evaluating projects
      - currently, who authors is the primary factor by which people evaluate projects
      - if you seem like you know enough, people will take you seriously

  - RAG pipeline - taken from a data pipeline
  - RAG observability - similar
  - llamaIndex - big framework announced "agents" (a hot thing)

- need to share and tell people what you've done, it's important

- large vs small models
  - RAG vs fine-tune
  - foundational models - not too many of them, fewer in open-source
    - foundational models cost billions to create
    - rest of the models are quantized, etc. they're smaller and depending how you slice, they do 80% of what you need
    - now hundreds of open-source models that are smaller, more specific, etc.
    - when we deploy them, we can use RAG, search-augmentation, etc. chunking strategies, etc.
    - layering things on top of this makes it difficult
    - everyone is just trying different approaches to see what works in what use cases


  - capstone project formula - rag pipeline with eval
    - we just build a oss version with a narrower use case, narrow, less features, easier to setup
    - our capstone project might include a 'how-to' blog article
    - lawyers - you pay a lot for them
      - you feel like you could have done exactly what they did - delegate to a junior, etc.

  - don't invent anything
    - we're interested in getting a job and not getting users
    - if I get users I can create a new market - but satisfying a latent demand is difficult - hard to gauge demand
      - we don't want to gamble with a new market
    - need to find a proven problem - someone needs to understand that problem right away
    - find an existing problem to tackle
    - rag with feature flag:  if we have a thought - need to validate - if it exists - product or project that exists then there's validation
    - make sure people use it - look for stars, activity, etc.

  - on an interview, the best reaction is - we've got that problem, too
    - don't want to have to tell people about the problem
    - you want people to ask about tell me about why you built it

- by end of this week, do up to end of lesson 5 fast.ai

- the vast majority of content is on the LLM side
  - mostly about creating LLMs
  - we could do it later

- re-assess by Wednesday
  - finish MS course this week (just review, dive into code later)
  - finish up to fast.ai 1 to 5 incl.
  - finish articles
  - next week we can start rag
  - we could write an article about AI/RAG after all this knowledge

- so much is happening live, in real-time on twitter, we should understand those conversations
  - focus on breadth-first approach
  - don't spend hours on setup


  