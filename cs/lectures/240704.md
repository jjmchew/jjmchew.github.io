# Thu Jul 4, 2024 - meeting with Chris

- Keep working through RAG reading
- it's early enough to build stuff and get traction - products require a lot of stitching together
  - the barrier is quite low at the moment
  - shared:  Andrej Karpathy post - why isn't it easier to stitch various AI services together to create video
  - e.g., used @AnthropicAI, @ideogram_ai, @LumaLabsAI, @elevenlabsio, @veedstudio

  - took an hour for 3 scenes

  - we don't have to create a "dev tool" - we could create a property

  - should start to get into the ideation space
  - prototypes will win - whoever has a working prototype is usually the direction that teams will move in

  - the work should be very similar - stitching together components or something else will be relatively similar

  - it's hard to estimate the amount of effort to stitch things together - could take an hour or it could have taken half a day

- e.g., Plinko project
  - drop a ball through a set of pegs and the ball can land in a few different buckets
  - Plinko - they made it multi-player, tried to make a real-time in-browser game
    - synchronizing game state across all browsers in very close to real-time
    - had to use a 3d physics engine in browser
    - it was a very impressive project - had to project where the state would go - made a guess and then had to sync this up
    - they ended up finding a blog post about how to sync real-time 
    - people didn't understand how complicated the game ended up being
  - no-one understood how complicated the project was
  - product is easy to demo, but it's hard to understand the effort involved
    - people might think it's a weekend project
    - people won't understand the effort

- a service-oriented project is generally easier to understand for people
- otherwise, it could be difficult in the interview stage

- most people will have enterprise AI experience
  - Chris is likely more informed that many other hiring managers

- want to do hands-on work - how to do that in a way that might be usable for the project
  - CL:  don't worry about making it relevant later
  - just do whatever - don't need to optimize
  - finding dead ends is good - great info
  - don't try to optimize too much
  - motion generates information; just do tight iterations
  - burning a day is not a big deal


- system designy infrastructure projects
  - it's hard to find something tangible
  - niches (e.g., CICD for mesh networks) - it could be interesting, but need to find existing solutions to see things that are a legitimate problem space
    - if you find a niche, the hard thing is finding a viable solution
    - nothing something huge, and not something "dead" (an old open-source project)
    - need to find something smaller than "open-source kafka"
    - there are a lot of model projects
    - there are too many problems and too many solutions

- for us, it will end up being a team preference, there are so many areas since there is so much new

- e.g., serverless projects - there were so many options - anything that wasn't serverless could be made serverless
  - first project was make a lambda with an API gateway
  - subsequent projects got more complicated
  - projects had to evolve with the market

- ChatGPT - you can use different languages to chat with ChatGPT

- course on Advanced Rag ($1600, 6 weeks long)
  - as the course progresses, Max will take it, and share info

- best to not deviate from RAG

- search as a problem domain is VERY big
  - it's outside of RAG and AI
  - search is big academically and application
  - too big to talk about - need to get specific
  - we're not going to build open source version of elastic search
  - search as a topic is too big - it's a whole other universe

- recommender systems was Chris' undergraduate thesis
  - it exists outside of AI
  - it's an area of deep speciality
  - don't use that word "recommender systems"
  - people get PhDs in that

- if we find an open source project that is similar to what we want to do and we remove some features
  - something semi-popular, semi-technical
  - make it AWS, etc.
  - focus on a specific use-case, etc.
  - if you have an open-source model project you can see the architecture
    - the reason why they do things is for reasons that they learn later on
    - that is ideal

- function-calling from LLMs
  - it could be part of RAG - it's how we interact with models
  - prompting and function calling is AI-specific
  - function calling is a feature - we could leverage

- seach as a feature is fine
  - recommending links is fine as a feature
  - wouldn't call that a "recommender system"

- Monsoon project:
  - they were talking about load testing
  - weren't sure what to do a project on
  - don't need to wildly speculate on a project
  - better to find existing projects
  - they found a bunch of projects, but it was hard to setup and make it work
  - then someone found something they could log into
    - then everyone understood how to make things possible
    - e.g., a question was how do we automate load testing - need to login and test other workflows
    - what code would you write to make this testing possible, write a script?  need to figure out what "normal" is
      - turned out there was an industry standard around this
      - they had to look at the existing project to better understand the boundaries of the problems
      - need to find a model project to log in and use it
    - before that, study and better understand the space
    - find something to log into

- UX - understands users better
  - often shuts down business people and engineers

- CL:  same as startups
  - we need to find projects that we can use that are the same "shape" as what we might want to work on
  - need to have real users
  - need to do a lot of research
  - could go and talk to other developers from those projects
    - great way to get insight from other devs
    - people like to talk about technical discussions
  - need to compress experience into a short amount of time
  - capstone is mostly a research project (unless you're doing a product)
    - then you might focus on product features(e.g., latency, dealing with lots of users, etc. answers come quickly, etc.)
  
  - figure out where local models are used, are there applications where local models are appropriate?
    - Capstone alum - they're using multiple models in their product.  the end user won't know what's happening - different models are used for different reasons
      - models could switch in 1 conversation

- TL: read an article about chunking strategies and embedding
  - from corpus:  any sentence embedding needs to match its context
  - idea for query elaboration(?)
  - CL:  need to find something else that is doing this
  - CL:  no invention - need evidence that it isn't something new


- we need to search for a model project
  - keep an eye out for model project or products

