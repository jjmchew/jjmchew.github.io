# Wed Aug 7, 2024

## Presentation with Derick Gross

- TL:  how familiar are you with GenAI, etc.
- DG:  familiar with Shawn Wang (?) - latentspace - 
  - he presented last year and they have a course, have been working on deploying the serverless application

(- forgot to record - sorry!
- need to better setup presentation for what kind of feedback we're looking for)

- TL:  presentation - 9:04 am start
  - (JC:  pace felt great, delivery was clear)
  - 9:12 am - finished mendable walkthrough
  - (JC:  DG nodded to the problem of privacy - not sending docs to OpenAI)
  - 9:13 am - component diagram
  - (JC: great to have gone slowly through this component diagram - it's a complicated diagram)
  - 9:16 am - architecture diagram
  - (JC:  could have mentioned "bursty" for ingestion)
  - GL:  9:18 am - walkthrough on knowledge base
  - (JC:  could have provided more transition to help viewer understand components and architecture - big step in presentation)
    - (JC:  may need to build up components, architecture more slowly - e.g., as Chris described, walking through the RAG process with the same set of steps)
    - (JC: describing pipeline seemed a bit confusing - might need to better setup embedding the query, describing context for genAI prompt)
    - GL:  described each path of evals (~ 9:23 am)
    - BB:  9:24 am start - describing benchmark evals
    - (JC:  could perhaps setup problem for why benchmark data is necessasry for evals - i.e., non-deterministic nature of LLMs)
    - BB:  9:25 am finished evals

  - GL:  talked about "why" of architecture

- DG:  a very interesting project
  - it would help to have a specific example - like what Ben mentioned during evals
  - having an example to work through might be helpful (e.g., onboarding docs for a new developer) - use that example to highlight details
  - DG:  is our architecture working?  Can we show an example of evals?
  - GL:  not yet working

  - DG:  has a particular framework in mind for how comparison of equality...
  - DG:  "Rag Triad"?
    - a way to compare various responses?
    - RAG triad:  context relevance, groundedness, answer relevance
    - he was expecting more discussion of those things - talking about OpenAI, was expecting to hear more about some framework for evaluating the responses
    - (JC:  need to use consistent terms - e.g., chatbot, e.g, LLM response, etc.  overall - need more structure to how we refer to things)
    - DG:  need to address the question of gauging the effectiveness of the responses from the LLM
      - talk about what's being compared and then how can we visualize what the evals look like
    
    - DG:  evaluations are stored in RDS?  have a mechanism to search RDS for specific instances of a chatbot and comparing instances over time?
      - is this meant to process multiple different higher-level chatbots?
      - e.g., onboarding chatbot vs FAQ chatbot - is there a mechanism for viewing different tabs, etc?
      - might need to only upgrade only the onboarding 

    - DG:  it feels like almost a separate project to have advanced work with the evals
      - it feels like the project of creating the dashboard around the rag system is pretty intense
      - is there a reason to scope the project at that level other than just dump into RDS?
    
      - BB:  we brought in a separate model project - since we didn't see a lot of projects that combined them
  
  - DG:  knowledge-base and ingestion section
    - pull the embedding out and having an EC2 instance to docDB
    - JC: considered use of llamaParse
    - DG:  red flag was llamaparse - don't want documents to end up anywhere else
    - JC:  what libraries did you use for ingestion?
      - DG:  tried to keep it simple - used boto3, openai, pandas, regex, tiktoken, langchain

  - DG:  is there a reason not to go with an API?
    - provide a set of APIs vs a react UI?
    - are we deploying a UI for the user?
    - (JC:  we could have talked about our users)
    - GL:  users have a UI for an admin, react component is for company owner for final user
      - queries can come from the react component that users interact with
  
  - DG:  this is a really big, ambitious project
    - instinct is that this is big
    - he'd be looking for places to scale back
    - we could just provide API endpoints - the team can make the API call
    - off-load that to the user

    - if they have to use the react components, it could be limiting for how that chatbot is used
      - if just an API, you could use "telegram", etc.
  
    - GL:  all the pieces are built, but we're working on integrating
      - things are breaking (DG - nods)
    
    - DG:  integrating is a hidden cost
      - complexity - there are so many hidden places to break down
      - lambda layer size? or run time?
    
      - GL:  we could recommend llamaparse, but we could take that out to simplify things

    - JC:  proposed lambda for "burstyness" - thoughts?
      - DG:  can deploy an EC2 with different specs
      - could play with it
      - DG:  wanted to use lambda for no long-running EC2 instances - user would be a small business owner - pay-as-you-use
      - if there isn't a use case for lambda, you could use auto-scaling EC2 instances
      - part of the challenge with ec2 is why long-running?  it can take a while to start the processing
        - but if we do batch processing of docs, if the expectation isn't "instant" than it might be very reasonable
        - use an auto-scaling group to scale to zero if there's no ingestion traffic


  - DG:  is python your only choice?
    - DG:  used github actions and CDK - can redeploy architecture - those deployments failed b/c of dependencies
    - DG:  it feels like once you get that settled, it should click and be easy to run
    - DG: need to think about use case - if it changes, it can invalidate the work, but think about the core functionality to provide
      - his instinct is that we want to store results in RDS, etc - but next step would be take on handling the evals to view, etc.
        - that could be it's own project
      - evals could be it's own project



## meeting w/ Chris
- CL:  today:  assess remainder of work on back-end today
  - we're about a week behind on write-up
  - there's a chance we could have Grace and Ben work on write-up as well as the front-end concurrently while the back-end is being done
  - CL:  concerned about timeline
  - CL:  TS option wouldn't be ideal - it's the "nuclear" option - would cost another week or 2
  - in that week or 2 you could have just got Python working

- CL:  simultaneously, we should start working on the write-up
  - CL:  write-ups have been started by 1 or 2 while the rest of the team keeps working

- CL:  how do we want to break-up work?

- GL:  mobbing - getting everything working
  - feels very close - need to test on the server
  - CL:  should we do a status update later
  - 


## meeting 2 w/ Chris
- CL:  llamaparse - could be okay
  - dropdown is the key
  - it can be replaced later
  - think about what infrastructure vs app is
    - i.e, mendable is NOT infra - they can see your data
    - but AWS can also see your data - but they're infra
    - if we justify llamaparse - we could consider it infrastructure vs app
    - we might say let's not use an APP, but we're not saying let's not use INFRA

- CL: played with the demo online
  - need to automate deployment?
  - freshen UI?  
  - prioritize UI for screenshotting for writeup
    -  need to show people how to use it - e.g., evals - need to show people how to tweak and think of showing scores changing
  - don't focus too much on things refreshing - that's okay - not the end of the world
  - GL:  no responsive design?
    - CL:  don't worry about it - could add media queries later
    - CL:  blocky UI should be easy to make responsive
    - would prioritize generate screenshots for the write-up
      - e.g., historical data, - show people how to use the tool, first run through, 2nd run through scores will change, etc.
      - show people the value, make a UI that shows that
      - it's hard jumping into a blank tool
      - when it's filled out it's much more interesting
    
  - the value and difference come later - so show that

  - automation story - don't worry about it
  - just automate deployment to ec2 for now for base feature set

- CL: MASHR past capstone project
  - they talk about data pipelines
  - this was an early capstone project
  - other people don't read past projects
  - they had a simple architecture - 1 large google cloud instance
    - GCP didn't hit that well (AWS is more popular)

  - they wrapped Embulk
    - hence, similar to our project
    - but our domain is more complicated, so need to articulate

    - had external dbs - they used different adapters they normalize it
    - the group was worried that embulk did so much work - such a big open-source tool, they didn't have to write adapters
    - compute engine = ec2;  dockerized it
      - sent stuff to cloud storage (s3)
    - project seemed like a simple architecture

    - don't worry that you HAVE to push to lambda - work on automated deployment
    - don't feel like you have to move to a serverless architecture - it's not hot anymore

    - if you can justify, great, if people ask - just defend the architecture - simple is great too
      - zoom into architecture and don't worry about not having a bunch of lambdas

    - automate deployment next (i.e., like Mashr)
    - we don't need a multi-tenant story

    - mashr didn't even have a UI

    - we have a UI, infra, domain story

- internship - you get paid
  - Rails (mastodon)
  - these are hard - they want you to stay longer
  - we can't commit to 6 months since we're looking for work
  - they need front-end work
  - CL looking for mastodon mentor for capstone grads - we can show up, work with mastodon, but need a mentor to help chop things up, help out with onramping, etc.



- open-source you have pay (just a little bit)
  - have some partners - good names for your resume
  - CL:  this week had some good offers both about $110k

  - online, people complain more - it's not good, but not as doom and gloom as people think

- CL:  need to show your work
  - do good work, get PRs submitted AND write blog posts
  - writing blog posts can be really helpful
  - especially if it comes out on the company blogs
  - it's really powerful - great way to self-promote and "speak up for yourself"

  - need to package things
    - need to market - e.g., startups - subpar product with good marketing makes a difference
  - writing is an easy way to do that

  - we'll talk about writeup tomorrow





